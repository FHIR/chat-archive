---
layout: page
title: "FHIR Chat  · AI generated clinical information · implementers"
---

{% raw %}<h2>Stream: <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/index.html">implementers</a></h2>
<h3>Topic: <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html">AI generated clinical information</a></h3>

<hr>

<base href="https://chat.fhir.org">

<head><link href="https://fhir.github.io/chat-archive/style.css" rel="stylesheet"></head>

<a name="273799268"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/273799268" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ardon Toonstra <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#273799268">(Mar 02 2022 at 12:34)</a>:</h4>
<p>How would you best represent clinical information in FHIR that is generated by an artificial intelligence system? For example, information that is suggested by a smart system for <code>ClinicalImpression.finding</code>. I think we want to be able to label or indicate that that information is authored by a system/device instead of a human. </p>
<p>So... extensions? Provenance? Do others have experience with AI-generated clinical information?</p>



<a name="273808810"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/273808810" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> David Winters <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#273808810">(Mar 02 2022 at 13:47)</a>:</h4>
<p>Not sure that is the intended use of ClinicalImpression.  What about capturing this using an Observation and using the <a href="https://www.hl7.org/fhir/observation-definitions.html#Observation.device">Observation.device</a> element to point to a Device resource that describes the AI?</p>



<a name="273824337"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/273824337" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mike Lohmeier <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#273824337">(Mar 02 2022 at 15:33)</a>:</h4>
<p>If the output of your modeling is part of decision support, you can leverage the RiskAssessment resource. The RiskAssessment resource has a <a href="https://www.hl7.org/fhir/riskassessment-definitions.html#RiskAssessment.performer">performer</a> field that can reference your AI system as a Device resource. </p>
<p>Otherwise, like David mentioned the Observation leveraging device makes sense, if the output of your modeling is not part of decision support like predicted data values for time series data.</p>



<a name="273917431"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/273917431" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Lloyd McKenzie <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#273917431">(Mar 03 2022 at 03:34)</a>:</h4>
<p>The AI would be represented as a Device.  It would be the author of the ClinicalImpression or whatever was being created</p>



<a name="274042490"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/274042490" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Mareike Przysucha <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#274042490">(Mar 03 2022 at 21:25)</a>:</h4>
<p>I think this tackles a more general question: if ClinicalImpression.finding contains a CodeableConcept, do we in general assume, that the assessor also made the finding?</p>
<p>Of yes: how do we cover AI as author, as ClinicalImpression only has an assessor, but no author, and assessor is limited to Practitioner and PractitionerRole. </p>
<p>If not: i would propose to use one of the resources named afterwards and set the author to the AI-device.</p>



<a name="274088829"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/274088829" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> René Spronk <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#274088829">(Mar 04 2022 at 07:04)</a>:</h4>
<p>The Provenance resource has a role to play in this scenario as well.</p>



<a name="274448253"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/274448253" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ardon Toonstra <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#274448253">(Mar 07 2022 at 19:54)</a>:</h4>
<p>Thanks all for the input! Very helpfull. Good to know an AI would be modeled as a Device that's inline with my thoughts as well. We are also investigating the use of the Provenance resource. </p>
<p>Also Josh noted me to this slightly related thread: <a href="#narrow/stream/179280-fhir.2Finfrastructure-wg/topic/NLP.20Derived.20Elements">#fhir/infrastructure-wg &gt; NLP Derived Elements</a></p>



<a name="274448628"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/274448628" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Ardon Toonstra <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#274448628">(Mar 07 2022 at 19:57)</a>:</h4>
<p>Can I conclude that it is not smart to mix AI generated information in resource that contain human made clinical content?</p>



<a name="274474306"></a>
<h4><a href="https://chat.fhir.org#narrow/stream/179166-implementers/topic/AI%20generated%20clinical%20information/near/274474306" class="zl"><img src="https://fhir.github.io/chat-archive/assets/img/zulip.svg" alt="view this post on Zulip" style="width:20px;height:20px;"></a> Lloyd McKenzie <a href="https://fhir.github.io/chat-archive/stream/179166-implementers/topic/AI.20generated.20clinical.20information.html#274474306">(Mar 07 2022 at 23:31)</a>:</h4>
<p>Mixing content - whether it's device + human or multiple humans can happen.  Whether it's problematic or not depends on how much you need to know exactly who's responsible for what.  In theory, even if you do combine into a single resource, Provenance can let you differentiate who's responsible for which elements.</p>


{% endraw %}
<hr><p>Last updated: Apr 12 2022 at 19:14 UTC</p>
