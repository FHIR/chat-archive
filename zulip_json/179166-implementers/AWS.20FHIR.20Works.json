[
    {
        "content": "<p>Hi All - Looking for some feedback / comment on using AWS FHIR work for FHIR implementation for our project. Does AWS FHIR uses HAPI behind the scene or custom development? </p>\n<p>Also wanted to check if need to buy license for production version of HAPI.</p>",
        "id": 252315795,
        "sender_full_name": "Nitin Suri",
        "timestamp": 1631025541
    },
    {
        "content": "<p>HAPI is open-source.  Smile CDR is the organization that provides commercial support for and enhanced function on top of HAPI</p>",
        "id": 252319559,
        "sender_full_name": "Lloyd McKenzie",
        "timestamp": 1631026924
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"191320\">Lloyd McKenzie</span> <a href=\"#narrow/stream/179166-implementers/topic/AWS.20FHIR.20Works/near/252319559\">said</a>:</p>\n<blockquote>\n<p>HAPI is open-source.  Smile CDR is the organization that provides commercial support for and enhanced function on top of HAPI</p>\n</blockquote>\n<p>Thanks <span class=\"user-mention\" data-user-id=\"191320\">@Lloyd McKenzie</span>  for quick response. It seems we can still run our application in production, built on HAPI w/o any license unless we need support or enhancements.  Any idea on AWS FHIR Works?</p>",
        "id": 252320247,
        "sender_full_name": "Nitin Suri",
        "timestamp": 1631027170
    },
    {
        "content": "<p>I'm afraid I can't speak to AWS</p>",
        "id": 252321103,
        "sender_full_name": "Lloyd McKenzie",
        "timestamp": 1631027546
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"191320\">Lloyd McKenzie</span> <a href=\"#narrow/stream/179166-implementers/topic/AWS.20FHIR.20Works/near/252321103\">said</a>:</p>\n<blockquote>\n<p>I'm afraid I can't speak to AWS</p>\n</blockquote>\n<p>No worries, i tried searching  for AWS FHIR Works Stream but could not find any in Zulip.</p>",
        "id": 252322178,
        "sender_full_name": "Nitin Suri",
        "timestamp": 1631028064
    },
    {
        "content": "<p>I don't believe AWS's FHIR implementation uses HAPI.   Here's an interesting article that compares AWS's  HealthLake to Google Cloud's Healthcare API. (it would be nice if there was also a comparison to Azure's FHIR implementation)</p>\n<p><a href=\"https://vneilley.medium.com/are-all-fhir-apis-the-same-v2-e8d8359e1412\">https://vneilley.medium.com/are-all-fhir-apis-the-same-v2-e8d8359e1412</a></p>",
        "id": 252323610,
        "sender_full_name": "John Silva",
        "timestamp": 1631028669
    },
    {
        "content": "<p>Part 1 of the blog post was on Google vs. Azure: <a href=\"https://vneilley.medium.com/are-all-fhir-apis-the-same-48be75ac4ac5\">https://vneilley.medium.com/are-all-fhir-apis-the-same-48be75ac4ac5</a></p>",
        "id": 252346393,
        "sender_full_name": "Paul Church",
        "timestamp": 1631037809
    },
    {
        "content": "<p>I'd love to see a summary/comparison of the data import/transformation pipeline features of platforms like Google and Azure.  As an EHR developer, I've started getting questions about how to sync data from our EHR into generic FHIR servers like Google and Azure.  Several folks I've talked to were de facto assuming that using a REST API (e.g. create/update) to load data into Azure/Google was the way to go, but often the data producers are not expecting to act as a FHIR client (and all the orchestration that involves).</p>",
        "id": 252347467,
        "sender_full_name": "Cooper Thompson",
        "timestamp": 1631038249
    },
    {
        "content": "<p>Because of that gap we have been almost exclusively working with data mapping pipelines from either v2 messages over MLLP or CSV files from a database as the ways to get data in from the EHR. It would be nice to get a better pattern for fhir-to-fhir replication. And of course for bidirectional use cases our service is not set up to be a FHIR client either!</p>",
        "id": 252348566,
        "sender_full_name": "Paul Church",
        "timestamp": 1631038694
    },
    {
        "content": "<p>That's exactly what I wanted/expected to hear.  Now I just need the Azure story...</p>",
        "id": 252349067,
        "sender_full_name": "Cooper Thompson",
        "timestamp": 1631038913
    },
    {
        "content": "<p>Where \"wanted/expected\" is in the context of short-term operational goals.  A standards based replication pattern long term would be nice, but seems... hard.</p>",
        "id": 252349218,
        "sender_full_name": "Cooper Thompson",
        "timestamp": 1631038971
    },
    {
        "content": "<p>The bulk data \"ping and pull\" proposal for import is one way to address this pattern: <a href=\"https://github.com/smart-on-fhir/bulk-import/blob/master/import-pnp.md\">https://github.com/smart-on-fhir/bulk-import/blob/master/import-pnp.md</a></p>\n<p>But this is bulk rather than streaming replication.</p>",
        "id": 252350148,
        "sender_full_name": "Paul Church",
        "timestamp": 1631039356
    },
    {
        "content": "<p>Subscriptions are the other relevant IG, but there needs to be an intermediate component that is receiving the notifications and acting as the client to the destination.</p>",
        "id": 252350438,
        "sender_full_name": "Paul Church",
        "timestamp": 1631039473
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"241501\">@Caitlin Voegele</span> <span class=\"user-mention\" data-user-id=\"195075\">@Brendan Kowitz</span></p>",
        "id": 252352991,
        "sender_full_name": "Gino Canessa",
        "timestamp": 1631040490
    },
    {
        "content": "<p>re: FHIR streaming/replication - A method we've used with in our own server development is to push a record into a stream/queue for every create, update, delete operation performed on a resource in a post-processing hook. </p>\n<p>Basically we push a message to a queue which contains the resource (or URL if the resource is too big for the queue), along with some metadata such as operation type, resource type, timestamp, etc. </p>\n<p>Then downstream of that we can add any consumers we want. Consumers to monitor for alert conditions, index data into secondary stores, anonymize and push to a second FHIR server, etc. It's a flexible model, but can make security more difficult.  </p>\n<p>I'm sure something similar could be done with the interceptor framework built into HAPI. I'm not aware if other implementations have anything similar.</p>",
        "id": 252375641,
        "sender_full_name": "Craig McClendon",
        "timestamp": 1631050757
    },
    {
        "content": "<p>Bulk export is spec'd and there seems to be implementations out there but bulk import is not yet at that point.  MS has a toolset that can import \"bulk export data\" (NDJSON) into Azure: <a href=\"https://github.com/microsoft/fhir-loader\">https://github.com/microsoft/fhir-loader</a></p>",
        "id": 252378431,
        "sender_full_name": "John Silva",
        "timestamp": 1631052441
    },
    {
        "content": "<p>In Azure there are a few items available around importing and exporting data. </p>\n<p>For export, both the Azure API for FHIR and the FHIR service in the Azure Healthcare APIs have the spec implemented. You can see details about that here: <a href=\"https://docs.microsoft.com/en-us/azure/healthcare-apis/data-transformation/export-data\">https://docs.microsoft.com/en-us/azure/healthcare-apis/data-transformation/export-data</a></p>\n<p>For import, the FHIR bulk data loader listed above is one option. Microsoft also recently added support for $import into the open-source FHIR server backed by SQL. The PR with this commit is here: <a href=\"https://github.com/microsoft/fhir-server/pull/1992\">https://github.com/microsoft/fhir-server/pull/1992</a></p>\n<p>If there are other questions, feel free to ping me.</p>",
        "id": 252638835,
        "sender_full_name": "Caitlin Voegele",
        "timestamp": 1631198931
    },
    {
        "content": "<p>AWS FHIR Works is open sourced under Apache 2.0. There are companies using it and the community is active with ~6-10 issues/PRs a week. The nice thing about AWS FHIR Works is that all underlying technologies are horizontally scaled out of the box and are rock solid. So, as long as you don't mind committing to the AWS cloud, you can spend less time on the undifferentiated heavy lifting and more time on your FHIR implementation. We stepped back and drew out how we'd implement a FHIR API in AWS natively and came up with the exact same architecture as AWS FHIR Works. So, it was better, faster and cheaper to run with AWS FHIR Works.</p>\n<p>AWS FHIR Works is a bit more immature than HAPI and isn't as ingrained with the healthcare community as some of the other OSS implementations. But sometimes that's a big positive. For example, they are asking the community right now for feedback on what use cases subscriptions will really be used. Instead of starting with the R4 spec for subscriptions that is a beast or the R4b spec which is much more tenable and work backwards from the use cases as opposed to the broad utopic specs. So far, they've landed on what I believe is a great out of the box subsection of FHIR R4 support that really gets the best pieces up and running while pushing off the features that aren't really being used in the field.</p>",
        "id": 255239545,
        "sender_full_name": "Mike Lohmeier",
        "timestamp": 1632844158
    },
    {
        "content": "<p>How do you feel that Firely compares to HAPI, Google, AWS and Azure?</p>",
        "id": 256657612,
        "sender_full_name": "Brian Beatty",
        "timestamp": 1633644436
    },
    {
        "content": "<p>Hey Folks!!<br>\nAnyone has any idea how to use AWS HealthLake API. I having issue on hitting the API, Permission Denied</p>",
        "id": 275328027,
        "sender_full_name": "Jayant Singh",
        "timestamp": 1647317903
    },
    {
        "content": "<p>I worked on a project last year where were we wrote our own custom import into Azure from CSV files, using the Firefly .NET sdk.  We were loading in about 200,000 patient record, with associated resources. It was extremely slow doing it record by record, taking about 2 seconds per record, with each record load hitting about 9 different API endpoints.</p>\n<p>No doubt there were faster ways to do this, but we were new to FHIR. It seemed to us at the time that there was a set of tools missing that would have made this easier. Configuration rather than having to write custom code.</p>",
        "id": 275376029,
        "sender_full_name": "Bill Quinn",
        "timestamp": 1647352673
    }
]