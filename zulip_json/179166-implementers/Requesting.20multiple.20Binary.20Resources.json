[
    {
        "content": "<p>It is possible request multiple binaries in their native format at once.  a la....</p>\n<p><code>get /Binary?_id=foo1,foo2,foo3...</code>?</p>",
        "id": 153964023,
        "sender_full_name": "Eric Haas",
        "timestamp": 1526968414
    },
    {
        "content": "<p>What would the output look like then?</p>",
        "id": 153964032,
        "sender_full_name": "Vadim Peretokin",
        "timestamp": 1526970655
    },
    {
        "content": "<p>I think that's possible.</p>",
        "id": 153964040,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1526976466
    },
    {
        "content": "<p>the result couldn't be a Bundle of Binary... would it be multiple mime parts?</p>",
        "id": 153964079,
        "sender_full_name": "John Moehrke",
        "timestamp": 1526992512
    },
    {
        "content": "<p>You could give it an accept header to get the binaries as resources rather than in their raw form.</p>",
        "id": 153964093,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1526999195
    },
    {
        "content": "<p>I want them in the raw form,  maybe a zip file?</p>",
        "id": 153964104,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527004964
    },
    {
        "content": "<p>otherwise a bundle of base64 encoded</p>",
        "id": 153964105,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527005046
    },
    {
        "content": "<p>For example I'm looking at grabbing a bunch of OMH datapoints in there original (json) format ... they are not very big and I may want several.  What if you want a bunch of progress notes ( aka text blobs) over the last 14 days.  You are options as the client are:</p>\n<ul>\n<li>make multiple calls to the endpoint</li>\n<li>get a bundle of Base64 encoded text blobs</li>\n<li>something else?</li>\n<li>JSON-LD?</li>\n</ul>",
        "id": 153964106,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527005257
    },
    {
        "content": "<p>On a similar note DocRef may return multiple urls so you might want to turn around and say \"get me all these\"</p>",
        "id": 153964107,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527005870
    },
    {
        "content": "<p>Is the issue searching and retrieving or just retrieving?  </p>\n<p>If searching too, you could do a DocumentReference search with an _include request for Binary.</p>",
        "id": 153964118,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527008234
    },
    {
        "content": "<p>just focused on retrieving....</p>",
        "id": 153964119,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527008273
    },
    {
        "content": "<p>the _include for Binary on DR is and open issue ( is not a type Reference but URL) ,  unless you hammered that out last week.</p>",
        "id": 153964120,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527008360
    },
    {
        "content": "<p>Ah, good point.  No, we didn't touch that last week.</p>",
        "id": 153964169,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527018981
    },
    {
        "content": "<p>I can't think of any options you haven't already enumerated.</p>",
        "id": 153964172,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527019032
    },
    {
        "content": "<p>Personally, I'd hit the endpoint multiple times.  The 33% overhead from base64 encoding would make the bundle approach enough more expensive (plus the decoding time on your end) that I think it'd be faster and easier to grab them one at a time.</p>",
        "id": 153964173,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527019118
    },
    {
        "content": "<p>depends on your latency. but why not ask for a zip containing them all?</p>",
        "id": 153964179,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1527019225
    },
    {
        "content": "<p>we could choose to say that's how to do things</p>",
        "id": 153964180,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1527019232
    },
    {
        "content": "<p>I meant NDJSON above not JSON-LD  ( for my json file use case)</p>",
        "id": 153964193,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527025474
    },
    {
        "content": "<p>is this something we should take for a test drive in clin-notes/omh  first before creating a tracker?</p>",
        "id": 153964194,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527025866
    },
    {
        "content": "<p>It's definitely worth talking over some more.  I don't have any theoretical objection to zipping binaries, but it wouldn't be a quick dev project for Epic, and our dance card is already quite full.  We can do individual downloads today (obviously) and could take a look at Binary search by ID to return a Bundle.</p>",
        "id": 153964195,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527027467
    },
    {
        "content": "<p>If you want to try it out, we've still got our system up from the Connectathon.  Postman collection here: <a href=\"https://www.getpostman.com/collections/80389c641f9570e2745b\" target=\"_blank\" title=\"https://www.getpostman.com/collections/80389c641f9570e2745b\">https://www.getpostman.com/collections/80389c641f9570e2745b</a></p>",
        "id": 153964196,
        "sender_full_name": "Michael Donnelly",
        "timestamp": 1527027548
    },
    {
        "content": "<p>In our experience, most of the UI around these looks at the list and loads the documents 1 by 1 based on what they care about</p>",
        "id": 153964354,
        "sender_full_name": "Jenni Syed",
        "timestamp": 1527093708
    },
    {
        "content": "<p>If we're talking about system to system use cases, that may start going more towards bulk data?</p>",
        "id": 153964355,
        "sender_full_name": "Jenni Syed",
        "timestamp": 1527093725
    },
    {
        "content": "<p>There are use cases where the binaries are not big enough or numerous enough to warrant bulk data.  I.m trying to access a bunch of fitbit data in raw form over a period of time.    You may have 10 or 20 smallish files.</p>",
        "id": 153964358,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527094694
    },
    {
        "content": "<p>Those normally wouldn't be documents in our system</p>",
        "id": 153964377,
        "sender_full_name": "Jenni Syed",
        "timestamp": 1527097603
    },
    {
        "content": "<p>or binary</p>",
        "id": 153964379,
        "sender_full_name": "Jenni Syed",
        "timestamp": 1527097635
    },
    {
        "content": "<p>...I know... but its my non EHR use case where a provider app is fetching from a FHIR endpoint and preserving the native format.  (I tried to make an analogy to all those short text blobby rounds notes type of \"clinical notes\" that you want to retrieve.  Maybe you want the whole weeks worth. )</p>",
        "id": 153964384,
        "sender_full_name": "Eric Haas",
        "timestamp": 1527097881
    }
]