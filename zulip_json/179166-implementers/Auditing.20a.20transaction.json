[
    {
        "content": "<p>I have a question regarding auditing of a FHIR transaction. Are we supposed to create one AuditEvent for the entire transaction bundle with type/subtype as rest/transaction? Or should we create one AuditEvent for each resource operation within the transaction bundle?</p>",
        "id": 153834869,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1466801268
    },
    {
        "content": "<p>I do both. But there's no formal policy</p>",
        "id": 153834901,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1466845886
    },
    {
        "content": "<p>Hi Anand,</p>",
        "id": 153834930,
        "sender_full_name": "John Moehrke",
        "timestamp": 1466888194
    },
    {
        "content": "<p>You can create one audit event that indicates as entities each of the items in transaction. You could create individual audit events for each item in the transaction.  You could even just do one audit event for the transaction, and N simple create/update audit events for the items. Or you could jut do one audit event for the transaction, create a Provenance for anything created/updated, and point the transactional audit evnent at the provenance.  This last part is what confuses the most, as it really indicates the overlap of provenance and auditevent. They are overlapped, but they have different downstream uses. So it is important to look at the downstream use-case, that will tell you which mode is likely most useful.... That said, not knowing the downstream, it is far better to create too many audit events as they are by nature less expected to be permenant and allowed to be analized and purged.</p>",
        "id": 153834931,
        "sender_full_name": "John Moehrke",
        "timestamp": 1466888446
    },
    {
        "content": "<p>The security wg would like to help the community understand proper use of auditEvent and Provenance through some connectathon focus. Today we have the EHR lifecycle that is fine for that specific purpose, but doesn't compel people to come test it. So we are thinking that what we need is some existing connectathon track that does something overall useful but also involved enough to have multiple actors and act upon multiple resources in an overall useful scenario. Security would then have an overlay on this indicating the points where Provenance might be critical, or useful; and where auditEvent might be criticalor useful. -- recognizing that  policy in a specific deployed implementation will actually define what is really required.   This way people can first focus on the primary purpose of the connectathon track, working on the interactions and clinical resource use; and then realize that for a bit more effort they can add support of the security layer...  </p>",
        "id": 153835078,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467035330
    },
    {
        "content": "<p>Unfortunately it seems all connectathon tracks are single resource focused and consist of only a client and a server. So it is hard to show value of audit or provenance; and adding these in without a larger context would look bizarre as the context less scenario would demand all involved create both audit events and provenance events; as there is no context to lend reasonable expectations.</p>",
        "id": 153835079,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467035457
    },
    {
        "content": "<p>+1 for security connectathon track(s)!  I'm concerned that the conformance resources as getting \"firm\" without enough information protection scrutiny...</p>",
        "id": 153835088,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467038382
    },
    {
        "content": "<p>Interesting... the Security WG could take a concentrated look at the security impact of the conformance resources... We are approaching an empty CP backlog...</p>",
        "id": 153835096,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467040513
    },
    {
        "content": "<p>That said... my point is that we have had a security track that no one signs up for.. the EHR lifecycle track... So, my proposal is not to have a security track, but rather to have security overlays on other tracks.</p>",
        "id": 153835097,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467040568
    },
    {
        "content": "<p>My concerns are that the conformance resources are useful in accurately conveying what's happening in a real-world system as information is redacted and/or updated during FHIR service calls.</p>",
        "id": 153835132,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467042812
    },
    {
        "content": "<p>Many interactions with clients are going to be on resources subsets...will the standard adequately communicate with the client regarding what information is being exchanged? Or will the server simply not send some information forcing the client to guess the meaning of missing data.</p>",
        "id": 153835133,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467042931
    },
    {
        "content": "<p>Or, prior to exchange, will it be possible for the client to determine a configuration based on what data the server will provide? Or will the client just have to start asking for data and then determine what it can do based on what is returned?</p>",
        "id": 153835134,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467042993
    },
    {
        "content": "<p>And now I'm off-topic for this thread....my apologies....</p>",
        "id": 153835135,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043022
    },
    {
        "content": "<p>Chris, we need to be careful. What you are asking for would expose the data that the system is protecting: \"Here is the data I have on the patient, except for that STD that the patient has asked us to not disclose\".</p>",
        "id": 153835136,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043561
    },
    {
        "content": "<p>We have mechanisms in FHIR to indicate that you have received ALL the data, or a SUBSET. This primarily so that you know you have a subset and thus an UPDATE would be difficult/impossible... (an operational problem we are kicking down the road, but at least we can detect it).</p>",
        "id": 153835137,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043645
    },
    {
        "content": "<p>Absolutely....but making a general statement that \"STD Observations will not be included in any request\" might be important</p>",
        "id": 153835138,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043649
    },
    {
        "content": "<p>Referring to the SUBSETTED tag?</p>",
        "id": 153835139,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043684
    },
    {
        "content": "<p>SUBSETTED is used when you have asked for a _summary... as an indication you didn't get it all.</p>",
        "id": 153835140,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043713
    },
    {
        "content": "<p>REDACT (or other) would be used if it was removed for a Security or Privacy reason</p>",
        "id": 153835141,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043730
    },
    {
        "content": "<p>but telling you WHY, is wrong.</p>",
        "id": 153835142,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043740
    },
    {
        "content": "<p>\"kicking down the road\" is exactly my concern...</p>",
        "id": 153835143,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043755
    },
    {
        "content": "<p>My lack of authorization to see birth date shouldn't (necessarily) prevent me from being able to update communication...</p>",
        "id": 153835144,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043816
    },
    {
        "content": "<p>we have enough problems to solve today... right?     This problem is where a user has less than full access, yet somehow has the rights to UPDATE? I don't understand why that use-case is important.</p>",
        "id": 153835145,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043820
    },
    {
        "content": "<p>your example is not likely... right?</p>",
        "id": 153835146,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043860
    },
    {
        "content": "<p>Because we want this standard to be useful in all kinds of environments! Sure it is</p>",
        "id": 153835147,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043878
    },
    {
        "content": "<p>you have rights to do an UPDATE on a resource, but you don't have rights to READ the whole thing?</p>",
        "id": 153835148,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043896
    },
    {
        "content": "<p>how is that even possible?</p>",
        "id": 153835149,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043904
    },
    {
        "content": "<p>AND the security layer is independent of the data-model... we are working on the data-model first.</p>",
        "id": 153835150,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043932
    },
    {
        "content": "<p>Think app market apps....there may be many scenarios where apps will operate only parts of resources</p>",
        "id": 153835151,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467043956
    },
    {
        "content": "<p>not that I want to paint myself into a corner.. which is why early this morning I suggested that this is useful for security to look at.</p>",
        "id": 153835152,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467043963
    },
    {
        "content": "<p>If apps work on only parts of resources, then we should take that as evidence that the resource is too big. I have argued many times that we need to be careful about making reources that are too big. That a criteria for how big a resource is should be how likely there would be policies that need to subdivide a resource. This should be used as clear evidence that the resource should be split.</p>",
        "id": 153835153,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467044067
    },
    {
        "content": "<p>If we were only working on the data model, I'd be calm.  But we're also very much working on the service model...</p>",
        "id": 153835154,
        "sender_full_name": "Chris Grenz",
        "timestamp": 1467044078
    },
    {
        "content": "<p>I have worked on a system where I had the right to enter a data value, but not the view the data I entered</p>",
        "id": 153835195,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467061022
    },
    {
        "content": "<p>HIV result. </p>",
        "id": 153835196,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467061028
    },
    {
        "content": "<p>I generally agree that the bigger a resource gets. the more likely it is to want to secure part of it, and that when they are too big, this will be a problem. But I don't agree that the correct size is 'when it's so small that no one will want to secure bits of it', so we will have to deal with that problem.</p>",
        "id": 153835198,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467061104
    },
    {
        "content": "<p>the problem with security at connectathons is time... security would have to be an outcome, not an overhead. (specifically with regard to the connectathon itself)</p>",
        "id": 153835199,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467061173
    },
    {
        "content": "<p>I wonder if it would be feasible to build a reusable HAPI server interceptor that automatically creates an AuditEvent for every incoming request. That would be really neat actually.</p>\n<p>Something to try at next connectathon perhaps. :)</p>",
        "id": 153835210,
        "sender_full_name": "James Agnew",
        "timestamp": 1467062233
    },
    {
        "content": "<p>I already do that internally</p>",
        "id": 153835218,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467063086
    },
    {
        "content": "<p>Same here.</p>",
        "id": 153835326,
        "sender_full_name": "Brian Postlethwaite",
        "timestamp": 1467077454
    },
    {
        "content": "<p>Yeah, your respective servers were the inspiration for this. :)</p>\n<p>I'm just wondering if it can be done generically enough to be useful (ie. could it be used on anyone's server if it's built with the HAPI server framework)</p>",
        "id": 153835327,
        "sender_full_name": "James Agnew",
        "timestamp": 1467077637
    },
    {
        "content": "<p>that sounds like a nice idea</p>",
        "id": 153835352,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467080401
    },
    {
        "content": "<p>so, this is nice... in that it does record AuditEvents for some security relevant events. However there are many more auditevents that need to be recorded. I would never discourage automation, I just want to keep the pressure on for complete auditevents. So, what events? Access Control decision failues, authentication failures, communication failures, storage failures, boot, system start, service managment, configuration management, and --- execution of services, workflows, algorithms, etc...</p>",
        "id": 153835357,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467080727
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191316\">@Grahame Grieve</span> I would never say to go too small... They need to be 'just right'... which is a tradeoff between many things. Sorry if I implied that we should make everything micro-resources. Not my intention. All I wanted was recognition that sometimes we should look to breakup a resouce because it is getting too big, too hard to manage. Yes I did propose that a trigger for this evaluation is when security would need to segment a resource, but this is just a trigger for evaluation, it is not a mandate that it must be broken up. I think we need some of these guiding principles.</p>",
        "id": 153835358,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467080916
    },
    {
        "content": "<p>agree. In fact, that particular rule is written somewhere, I think </p>",
        "id": 153835360,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467081054
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> having thought of creating audit events inside security labeling interceptor, I was wondering whether there is a mechanism to create/update resources from within an interceptor without actually establishing a TCP connection to the local server. Something like a special HAPI FHIR client that connects to the data source directly but maintains the HAPI client interface. </p>",
        "id": 153835911,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1467309182
    },
    {
        "content": "<p>sounds dangerous from within an interceptor... locking problems arise easily</p>",
        "id": 153835957,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1467322125
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191316\">@Grahame Grieve</span> I think if one uses the JPA transaction manager those issues are going to be taken care of. </p>",
        "id": 153835965,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1467325629
    },
    {
        "content": "<p>And if the transaction fails and is rolled back, need to be careful that the audit doesn't rollback too.</p>",
        "id": 153836007,
        "sender_full_name": "Brian Postlethwaite",
        "timestamp": 1467343688
    },
    {
        "content": "<p>If you mean within the JPA module you could do this by asking spring for a copy of the <code>IResourceDao&lt;AuditEvent&gt;</code> and wiring that into your interceptor. Then in your interceptor you could use that to write new AuditEvent resources.</p>\n<p>Look at the <code>IJpaServerInterceptor</code> interface, which adds some new methods to the interceptor. These methods are called within the scoping transaction so you could get all-or-nothing behaviour when writing an audit event alongside the thing you are actually writing (presumably you'd want this behaviour).</p>",
        "id": 153836318,
        "sender_full_name": "James Agnew",
        "timestamp": 1467670914
    },
    {
        "content": "<p>We had done a lot around avoiding this behavior i.e. failure in creating/updating a resource should NOT fail writing the audit event. At the same time failing a resource create/update if the creation of audit event fails is a desirable behavior.</p>",
        "id": 153836562,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1467779975
    },
    {
        "content": "<p>I don't think I agree. We even made statements to this in the core ATNA standards. The loss of an audit event is less important than the loss of medical data. Don't roll back something because you couldn't record the audit event. The audit needs to be as clean and fast as possible. </p>",
        "id": 153836588,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467812724
    },
    {
        "content": "<p>This article is about this concept, although the reason the article was written was different. But the concept is the same. <a href=\"https://healthcaresecprivacy.blogspot.com/2011/12/atna-syslog-is-good-enough.html\" target=\"_blank\" title=\"https://healthcaresecprivacy.blogspot.com/2011/12/atna-syslog-is-good-enough.html\">https://healthcaresecprivacy.blogspot.com/2011/12/atna-syslog-is-good-enough.html</a></p>",
        "id": 153836589,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467812768
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"192218\">@Anand Mohan Tumuluri</span> FWIW the interceptor in this case does also let you record a different audit event scoped outside the transaction in the event that the transaction rolls back, via the <code>handleException</code> method. It seems weird to me that someone would want the <em>same</em> audit event recorded for a write transaction, even if that write didn't actually succeed.</p>\n<p>The behaviour John is describing would be a bit more work though. Since the write and the audit-write are grouped, either could fail the other. I guess a queueing mechanism of some sort would be needed to separate these.</p>",
        "id": 153836591,
        "sender_full_name": "James Agnew",
        "timestamp": 1467813330
    },
    {
        "content": "<p>If the primary write failed, then the auditEvent.outcome should indicate the failure vs success. So it isn't really radically diffeent audit log entry.</p>",
        "id": 153836594,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467814558
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span>  I think I didn't say that right. If a resource CRUD failed, we write a failure audit event. The audit event write (success/failure) is not in the same transaction as the resource. In our case, the resource write is a sub-transaction yielding a operation outcome. The outcome is audited no matter what in the parent transaction. </p>",
        "id": 153836614,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1467823809
    },
    {
        "content": "<p>Well done. I expected so, but wanted to be clear.</p>",
        "id": 153836616,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467824430
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191404\">@John Moehrke</span> Isn't it subjective to allow/disallow resource actions without a audit trail? Is there enough consensus that it is OK to allow the resource action even if the audit couldn't be recorded.</p>",
        "id": 153836617,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1467824525
    },
    {
        "content": "<p>BTW very informative article, thanks for sharing</p>",
        "id": 153836618,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1467824647
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"192218\">@Anand Mohan Tumuluri</span> correct to note that this is clearly a policy statement; however I would argue that the in healthcare treatment the dominant policy is the one I ascribe. If we were in the Financial market, they would set the policy completely the opposite way; that is if it can't be written into the ledger then it can't happen. The difference is that in Finance the harm of delaying a transaction until the full system is operational is minimal, where in healthcare treatment the delay can cause pain, suffering, and death.    -- as a general-purpose toolkit, you don't know if you are being used for life-critical treatment, or if you are being used for delayable use-cases.</p>",
        "id": 153836621,
        "sender_full_name": "John Moehrke",
        "timestamp": 1467825320
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191404\">@John Moehrke</span> Thank you, I am more convinced than before.</p>",
        "id": 153836629,
        "sender_full_name": "Anand Mohan Tumuluri",
        "timestamp": 1467825826
    },
    {
        "content": "<p>Hi <span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> . Working on a consent enforcer interceptor for the Baltimore connecrathon, and following your advice above, I am now facing this exception trying to get a Dao for Patient or Consent. Wondering how I can trigger the creation of these beans:</p>\n<div class=\"codehilite\"><pre><span></span>No qualifying bean of type [ca.uhn.fhir.jpa.dao.IFhirResourceDao] found for dependency [ca.uhn.fhir.jpa.dao.IFhirResourceDao&lt;org.hl7.fhir.dstu3.model.Patient&gt;]: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}; nested exception is\norg.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type [ca.uhn.fhir.jpa.dao.IFhirResourceDao] found for dependency [ca.uhn.fhir.jpa.dao.IFhirResourceDao&lt;org.hl7.fhir.dstu3.model.Patient&gt;]: expected at least 1 bean which qualifies as autowire candidate for this dependency. Dependency annotations: {@org.springframework.beans.factory.annotation.Autowired(required=true)}\n    org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor$AutowiredFieldElement.inject(AutowiredAnnotationBeanPostProcessor.java:569)\n</pre></div>",
        "id": 153843876,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1471049157
    },
    {
        "content": "<p>That's very strange. Those should be created automatically.. Does it help if you ask for it by name? <code>myPatientDaoDstu3</code></p>\n<p>It gets declared in <code>BaseJavaConfigDstu3.java</code> FWIW</p>",
        "id": 153845231,
        "sender_full_name": "James Agnew",
        "timestamp": 1472210849
    }
]