[
    {
        "content": "<p>How would you best represent clinical information in FHIR that is generated by an artificial intelligence system? For example, information that is suggested by a smart system for <code>ClinicalImpression.finding</code>. I think we want to be able to label or indicate that that information is authored by a system/device instead of a human. </p>\n<p>So... extensions? Provenance? Do others have experience with AI-generated clinical information?</p>",
        "id": 273799268,
        "sender_full_name": "Ardon Toonstra",
        "timestamp": 1646224452
    },
    {
        "content": "<p>Not sure that is the intended use of ClinicalImpression.  What about capturing this using an Observation and using the <a href=\"https://www.hl7.org/fhir/observation-definitions.html#Observation.device\">Observation.device</a> element to point to a Device resource that describes the AI?</p>",
        "id": 273808810,
        "sender_full_name": "David Winters",
        "timestamp": 1646228843
    },
    {
        "content": "<p>If the output of your modeling is part of decision support, you can leverage the RiskAssessment resource. The RiskAssessment resource has a <a href=\"https://www.hl7.org/fhir/riskassessment-definitions.html#RiskAssessment.performer\">performer</a> field that can reference your AI system as a Device resource. </p>\n<p>Otherwise, like David mentioned the Observation leveraging device makes sense, if the output of your modeling is not part of decision support like predicted data values for time series data.</p>",
        "id": 273824337,
        "sender_full_name": "Mike Lohmeier",
        "timestamp": 1646235180
    },
    {
        "content": "<p>The AI would be represented as a Device.  It would be the author of the ClinicalImpression or whatever was being created</p>",
        "id": 273917431,
        "sender_full_name": "Lloyd McKenzie",
        "timestamp": 1646278499
    },
    {
        "content": "<p>I think this tackles a more general question: if ClinicalImpression.finding contains a CodeableConcept, do we in general assume, that the assessor also made the finding?</p>\n<p>Of yes: how do we cover AI as author, as ClinicalImpression only has an assessor, but no author, and assessor is limited to Practitioner and PractitionerRole. </p>\n<p>If not: i would propose to use one of the resources named afterwards and set the author to the AI-device.</p>",
        "id": 274042490,
        "sender_full_name": "Mareike Przysucha",
        "timestamp": 1646342759
    },
    {
        "content": "<p>The Provenance resource has a role to play in this scenario as well.</p>",
        "id": 274088829,
        "sender_full_name": "Ren√© Spronk",
        "timestamp": 1646377474
    },
    {
        "content": "<p>Thanks all for the input! Very helpfull. Good to know an AI would be modeled as a Device that's inline with my thoughts as well. We are also investigating the use of the Provenance resource. </p>\n<p>Also Josh noted me to this slightly related thread: <a href=\"#narrow/stream/179280-fhir.2Finfrastructure-wg/topic/NLP.20Derived.20Elements\">#fhir/infrastructure-wg &gt; NLP Derived Elements</a></p>",
        "id": 274448253,
        "sender_full_name": "Ardon Toonstra",
        "timestamp": 1646682859
    },
    {
        "content": "<p>Can I conclude that it is not smart to mix AI generated information in resource that contain human made clinical content?</p>",
        "id": 274448628,
        "sender_full_name": "Ardon Toonstra",
        "timestamp": 1646683046
    },
    {
        "content": "<p>Mixing content - whether it's device + human or multiple humans can happen.  Whether it's problematic or not depends on how much you need to know exactly who's responsible for what.  In theory, even if you do combine into a single resource, Provenance can let you differentiate who's responsible for which elements.</p>",
        "id": 274474306,
        "sender_full_name": "Lloyd McKenzie",
        "timestamp": 1646695873
    }
]