[
    {
        "content": "<p>Hi, i’m not entirely sure whether this is the correct stream for my question (telling me which one is better would be appreciated:-) ) but since I’m dealing with a Hapi Fhir service this is my best guess. <br>\nMy question is regarding getting the Fhir data in RDF in order to load it into a graph database like neo4j or, preferably, Dgraph. The Fhir spec has some minimal information and refers to the hapi reference implementation but I was unable to find any information or examples on the hapi site or in the hapi documentation. <br>\nMy understanding is that it is possible to export the Fhir data in RDF and some of the standard Fhir ontologies are made available. How to actually get that data is not documented anywhere as far as I could see. <br>\nDoes anyone here know where I can find more information on how to do this with Hapi specifically or does anyone know of a generic way to get Structured Fhir data into a graph database? Or better yet, is there any Fhir implementation that uses a graph database as their data store?</p>",
        "id": 154025998,
        "sender_full_name": "Simon de turck",
        "timestamp": 1545079198
    },
    {
        "content": "<p>Here's the situation as I understand it:</p>\n<ul>\n<li>the definitions of the spec itself are available in turtle format from the downloads page</li>\n<li>HAPI doesn't support RDF natively, but does include the class org.hl7.fhir.r4.formats.RdfParser that can convert resources to turtle</li>\n<li>I don't know of any open source implementations that use a graph database in the RDF sense. And the only commercial one I know about is (or has been) migrating to hadoop using json</li>\n</ul>",
        "id": 154026015,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1545082304
    }
]