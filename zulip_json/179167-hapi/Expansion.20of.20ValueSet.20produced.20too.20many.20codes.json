[
    {
        "content": "<p>Are folks seeing this (<code>Expansion of ValueSet produced too many codes (maximum 1,000) - Operation aborted!</code>) and how are you dealing with it?  I'm trying to use $expand and filter on the full ICD-10-CM code system (definitely &gt; 1000 codes) and am running into this issue.  Narrowing the returned results by using the filter and also trying setting the $expand 'count' parameter to a low value (e.g. 20) doesn't help eliminate the error (on HAPI 5.3.0 jpaserver-starter).</p>",
        "id": 233534338,
        "sender_full_name": "Rob Hausam",
        "timestamp": 1617818278
    },
    {
        "content": "<p>Once for me.  I couldn't remember the details or my response clearly, with v5.1.0 or v5.2.0.</p>",
        "id": 233584086,
        "sender_full_name": "Lin Zhang",
        "timestamp": 1617841571
    },
    {
        "content": "<p>Thanks, Lin.  And I'm still looking for how to fix it.</p>",
        "id": 233584693,
        "sender_full_name": "Rob Hausam",
        "timestamp": 1617842014
    },
    {
        "content": "<p>The code system and value set have 95587 codes, so the pre-expansion took a considerable amount of time.  But now that it is finally complete, the \"too many codes\" issue seems to be no longer occurring.  I assume that is expected (and I think it makes sense that it would be)?</p>",
        "id": 233587711,
        "sender_full_name": "Rob Hausam",
        "timestamp": 1617844350
    },
    {
        "content": "<p>Hi Rob and Lin<br>\nValue set expansion worked in a background job that is running after submitting new value set, in case you called $expand before the expansion is finished (once vs is expanded its concepts is stored in database and its status switched to expanded), the expansion will be running on RAM to return the result, hence the vs is larger than 1000 it will throw this exception \"too many codes\" .</p>\n<p>If you wait till the job is finished and all concepts stored in db and status is switched from in progress to expanded, then you won't have this exception any more</p>",
        "id": 233628223,
        "sender_full_name": "Hanan Awwad",
        "timestamp": 1617875775
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"279021\">@Hanan Awwad</span>  Wow, Thanks</p>",
        "id": 233643140,
        "sender_full_name": "Lin Zhang",
        "timestamp": 1617884677
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"279021\">@Hanan Awwad</span> Yes, that's exactly what I saw.  What wasn't clear in advance, though, was the schedule for performing the expansion and the amount of time to expect that it would take.  It just requires a bit of patience! :)</p>",
        "id": 233643362,
        "sender_full_name": "Rob Hausam",
        "timestamp": 1617884786
    },
    {
        "content": "<p>Related question: how do you know when the expansion is complete?   Doe HAPI log something that indicated \"expansion complete\"?<br>\nI tried running the <a href=\"https://github.com/hapifhir/hapi-fhir-jpaserver-starter#running-via-docker-hub\">Docker HAPI server</a> and loaded a large CodeSystem and ValueSet that referenced it and I couldn't tell if the expansion ever completed or if the docker image just ran out of RAM or (image) disk space.   I could only determine that the codes I was expecting to be loaded were not there when I performed the .../$expand?filter search.</p>",
        "id": 233681070,
        "sender_full_name": "John Silva",
        "timestamp": 1617897972
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"298707\">@John Silva</span> , either you could check the status for vs in db it should be expanded or you could debug the job that implemented inside BaseTermReadSvcImpl class</p>",
        "id": 233716848,
        "sender_full_name": "Hanan Awwad",
        "timestamp": 1617911256
    },
    {
        "content": "<p>Thanks.  I'm not familiar with HAPI enough to debug this and it's happening \"inside\" the Docker container so it's not easy for me to debug.  I was hoping that something is logged which I can see that indicates that the expansion completed (or not).    I'm running the docker container like this so the logs come right on standard output:</p>\n<p><code>docker run -p 8080:8080  hapiproject/hapi</code></p>",
        "id": 233723715,
        "sender_full_name": "John Silva",
        "timestamp": 1617914094
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"298707\">@John Silva</span>  In case its running well, for sure you will see some logs from BaseTermReadSvcImpl  class like the following <br>\nourLog.info(\"Pre-expanded ValueSet[{}] with URL[{}] - Saved {} concepts in {}\", valueSet.getId(), valueSet.getUrl(), accumulator.getConceptsSaved(), sw.toString());</p>",
        "id": 233727079,
        "sender_full_name": "Hanan Awwad",
        "timestamp": 1617915606
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"298707\">@John Silva</span> : I'm not really familiar with HAPI but  I think you can try the SpringBoot version (I tried it with starter project) which is easier to see the log and config the JVM</p>",
        "id": 233824685,
        "sender_full_name": "Jame Dang",
        "timestamp": 1617976503
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> : I tried the HAPI client to search with 5.4.0 PRE5 and the response.getTotal() always return 0 if I put the offset parameter (without the offset it is OK)? Maybe this is a bug of the HAPI 5.4.0 PRE5 ? Thanks and regards</p>",
        "id": 233944883,
        "sender_full_name": "Jame Dang",
        "timestamp": 1618050829
    },
    {
        "content": "<p>Can you replicate this on <a href=\"http://hapi.fhir.org\">hapi.fhir.org</a>?</p>",
        "id": 233959713,
        "sender_full_name": "James Agnew",
        "timestamp": 1618065180
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> : I have tried to connect to <a href=\"http://hapi.fhir.org\">hapi.fhir.org</a> (<a href=\"http://hapi.fhir.org/baseR4\">http://hapi.fhir.org/baseR4</a>), it has the same problem  and even I remove the offset parameter the total always return 0, in the 5.4.0 PRE5 if we remove the offset it is OK. I think the <a href=\"http://hapi.fhir.org\">http://hapi.fhir.org</a> is older than than the  5.4.0 PRE5 (which I'm using for my server), you can see <a href=\"http://hapi.fhir.org/baseR4/Patient\">http://hapi.fhir.org/baseR4/Patient</a> the total is not exist (so I think it has problem).</p>\n<p>For my server (using  5.4.0 PRE5) when I tried the link : /Patient?_getpagesoffset=2&amp;_count=1 I it run OK and I can see the total.</p>\n<p>But when I use the HAPI Client (see the code bellow) the result show me the link /Patient?_count=1&amp;_offset=1 (I think the java client convert wrong parameter ) </p>\n<p>The code I used for testing:<br>\n          FhirContext ctx = FhirContext.forR4();<br>\n          serverBaseUrl=\"<a href=\"http://hapi.fhir.org/baseR4\">http://hapi.fhir.org/baseR4</a>\";<br>\n          IGenericClient client = ctx.newRestfulGenericClient(serverBaseUrl);<br>\n          // Build a search and execute it<br>\n          Bundle response = client<br>\n                  .search()<br>\n                  .forResource(Patient.class)<br>\n//                .count(10)<br>\n//                .offset(1)<br>\n                  .returnBundle(Bundle.class)<br>\n                  .execute();<br>\n          System.out.println(\"Number of Responses: \" + response.getTotal());//Always 0</p>",
        "id": 233974372,
        "sender_full_name": "Jame Dang",
        "timestamp": 1618077465
    },
    {
        "content": "<p>I'm not sure I follow. That client code you quoted is for a Patient search,<br>\nnot a ValueSet expansion. The test server is not configured to support<br>\noffset searching for resources.</p>",
        "id": 233975219,
        "sender_full_name": "James Agnew",
        "timestamp": 1618078306
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> : I got it, but can I report the problem of the search function some where? Maybe that is a problem (I'm not sure but maybe that is a bug, I will try to see the config for offset searching)</p>",
        "id": 233975407,
        "sender_full_name": "Jame Dang",
        "timestamp": 1618078518
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191319\">@James Agnew</span> : Sorry for inconvenience, I tried to add the .totalMode(SearchTotalModeEnum.ACCURATE) to my search and the result is OK now (I got the total).  Thank you for your support</p>",
        "id": 233978199,
        "sender_full_name": "Jame Dang",
        "timestamp": 1618080874
    }
]