[
    {
        "content": "<p>Forgive me if I am looking in the wrong place, but I was curious if there was prior discussion/docs around the reverse mechanics of $export. E.g. to take the result and send it off to .../$import. In effect, a way to transfer data in bulk between FHIR Server A and FHIR Server B?</p>",
        "id": 153951131,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1522989703
    },
    {
        "content": "<p>this is exactly the right place, but to my knowledge there has been no such prior discussion. Now that you've raised it, I can't think why we've never talked about it</p>",
        "id": 153951132,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1522990366
    },
    {
        "content": "<p>Ah well, wonderful! So, is opening an issue (or PR?) in <a href=\"https://github.com/smart-on-fhir/fhir-bulk-data-docs\" target=\"_blank\" title=\"https://github.com/smart-on-fhir/fhir-bulk-data-docs\">https://github.com/smart-on-fhir/fhir-bulk-data-docs</a> the right place to raise a draft for a possible addition to the spec? I'd be happy to elaborate on implementation details/use cases.</p>",
        "id": 153951133,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1522990609
    },
    {
        "content": "<p>that would be right, but it would probably be appropriate to bash the ideas around a bit here</p>",
        "id": 153951134,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1522991013
    },
    {
        "content": "<p>Alright, so a couple use cases come to mind...</p>",
        "id": 153951135,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1522991419
    },
    {
        "content": "<p>A team has a QA FHIR Server which has canonical test data. That team also has many application developers that have local FHIR servers. For development, rather than copying all of the QA FHIR data or the entire DB, they only want to issue an $export of certain data and pipe the results into $import of their local test server. It's trivial to reset the local server but it's time consuming to create an maintain DB migrations. FHIR $export/$import to the rescue!</p>",
        "id": 153951136,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1522991467
    },
    {
        "content": "<p>Another use case is to provide a application-level mechanism for moving data between a production FHIR server and FHIR servers used for data analysis and model development -- effectively, $export/$import is a way for data scientists to move FHIR data off production without needing to learn about the underlying DB and migration capabilities.</p>",
        "id": 153951137,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1522991605
    },
    {
        "content": "<p>Hey Kurt! </p>\n<p>Of course, I've got nothing against improving your internal ETL or developer checkout processes -- both sound like worthy goals! I question if these features need to part of the standard interoperability spec ... ? </p>\n<p>The use-cases for $export, at least, will hopefully end up targeted to specific interoperability use-cases. (I'm not very familiar with $import, but presume that it should be flexible enough to consume FHIR generated from all types of operations/queries).</p>\n<p>What addition to the spec are you envisioning?</p>\n<p>Isaac</p>",
        "id": 153951138,
        "sender_full_name": "Isaac Vetter",
        "timestamp": 1522992294
    },
    {
        "content": "<p>well, $import is not presently defined... so I think Kurt envisions the complementary definition for $import as for $export</p>",
        "id": 153951142,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1522995559
    },
    {
        "content": "<p>Grahame, Kurt, In the light of day ... </p>\n<p>So, a $import would just place more of the burden of the data load process on the client; but otherwise could serve all of the same use-cases. Actually, this sounds like a really nice feature and probably is necessary for the bulk api to be well-rounded.</p>",
        "id": 153951165,
        "sender_full_name": "Isaac Vetter",
        "timestamp": 1523024037
    },
    {
        "content": "<p>I agree. Having $import as the other side of the coin make sense. I do wonder about how you track where the data came from... I guess Provenance would come into play here. Also -- what to do about conflicts (e.g. resource ids, among other things)? The system executing the $import might not be empty...</p>",
        "id": 153951168,
        "sender_full_name": "Jason Walonoski",
        "timestamp": 1523024614
    },
    {
        "content": "<p>I love this concept -- and hey <span class=\"user-mention\" data-user-id=\"195435\">@Kurt Ericson</span>, great to have you here! I wonder if we could make a quick sketch (e.g. in a GH issue) showing what a minimal surface area might look like. <span class=\"user-mention\" data-user-id=\"191381\">@Jason Walonoski</span> is asking the right questions. Is your main use case to populate an <em>empty</em> server?</p>",
        "id": 153951170,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523024927
    },
    {
        "content": "<p>Also, a meta-point about naming: <code>$import</code> feels like such a natural counterpoint to <code>$export</code>. This speaks to the good sense of our <code>$everything</code> -&gt; <code>$export</code> transition :-)</p>",
        "id": 153951171,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523025041
    },
    {
        "content": "<p>I would like to help profile Provenance so that it can best match the bulk data use-case. How does one represent consistently the who, what, where, when, why... when the 'how' was a bulk data export or import...</p>",
        "id": 153951187,
        "sender_full_name": "John Moehrke",
        "timestamp": 1523029482
    },
    {
        "content": "<p><span class=\"user-mention\" data-user-id=\"191315\">@Josh Mandel</span> sounds good -- glad to be here; I'll create an issue with more detail about the idea; the initial use case i was imagining was from a populated server to an empty server. However, i can also easily imagine cases where it's from a populated server to another populated server (e.g. perhaps a nightly operation that moves certain resources from Prod Server-&gt;$export-&gt;DeId Workflow-&gt;$import-&gt;Researcher Server)</p>",
        "id": 153951192,
        "sender_full_name": "Kurt Ericson",
        "timestamp": 1523032387
    },
    {
        "content": "<p>Vonk has had it's proprietary /preload function for a while already, but I'd like to see that turned into something standardized. It currently allows for a zip file with a bunch of resource files in it (either json or xml). Which turns out to be fairly useful for e.g. a fixed test dataset of limited size. We use it to upload the examples from the spec. So maybe $import can be a bit more versatile in formats than $export: zip; collection bundles; ndjson?</p>",
        "id": 153951230,
        "sender_full_name": "Christiaan Knaap",
        "timestamp": 1523039912
    },
    {
        "content": "<p>Yeah. I am imagining the key use cases will be for passing sets of resources directly to the import endpoint versus passing a manifest of pointers</p>",
        "id": 153951231,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523039987
    },
    {
        "content": "<p>In the simplest case posting a transaction bundle to <code>/</code> works well enough for small data.</p>",
        "id": 153951232,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523040009
    },
    {
        "content": "<p>But we want to have a clear path towards larger sets of data.</p>",
        "id": 153951234,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523040104
    },
    {
        "content": "<p>For larger dataset the async pattern invented for $export will be useful.</p>",
        "id": 153951236,
        "sender_full_name": "Christiaan Knaap",
        "timestamp": 1523040157
    },
    {
        "content": "<p>Quite</p>",
        "id": 153951238,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523040174
    },
    {
        "content": "<p>It could get time consuming to evaluate authorization for all the resources in the import set, especially if a compartment / patient scope has to be honoured. I would prefer authorization on an operation level: if you are allowed to do $import, you can import anything you like. Which also aligns with the usecases outlined above.</p>",
        "id": 153951240,
        "sender_full_name": "Christiaan Knaap",
        "timestamp": 1523040376
    },
    {
        "content": "<p>Hey <span class=\"user-mention\" data-user-id=\"191757\">@Christiaan Knaap</span> ,  <span class=\"user-mention\" data-user-id=\"191315\">@Josh Mandel</span> , All - targeting ETL as the primary use-case means that we'll likely exclude production interoperability uses.  </p>\n<p>Authorizing a client to $import anything and everything at the root level of the FHIR server is a great example of why the use-case matters. Practically, authorization would occur at the server level (for ETL and other IT uses), Group and probably resource+operation as well depending upon the use-case. </p>\n<p>This might be good fodder for the SMART scopes discussion / redesign.</p>",
        "id": 153951241,
        "sender_full_name": "Isaac Vetter",
        "timestamp": 1523040751
    },
    {
        "content": "<p>Authorization on operations is still a green field as a whole, but indeed better fitted for the smart stream.</p>",
        "id": 153951243,
        "sender_full_name": "Christiaan Knaap",
        "timestamp": 1523040929
    },
    {
        "content": "<p>Authorizing is necessary. YUP, Privacy and Security are necessary... It is very possible to have a use-case that can be authorized at the root level. But you must do the use-case analysis as Isaac has pointed out.   There is nothing HL7 or Argonaut or even HHS/ONC can say that compels the elimination of the Authorization responsibility.</p>",
        "id": 153951244,
        "sender_full_name": "John Moehrke",
        "timestamp": 1523040963
    },
    {
        "content": "<p>If we take the generalized use-case where the requesting actor does have &lt;read&gt; authorization for everything from the root.. what might a simple scope look like? Is it other than \"user/*.read\"? How is that not sufficient? Yes it recognizes that the requesting agent is referenced as a 'user', but this is often how a client agent organization is recognized in authorization policy.</p>",
        "id": 153951246,
        "sender_full_name": "John Moehrke",
        "timestamp": 1523041398
    },
    {
        "content": "<p>As Isaac mentions, there is effort on at this point to advance the scope design. See the dedicated Stream for Privacy and Security, specifically the thread <a href=\"https://chat.fhir.org/#narrow/stream/Security.20and.20Privacy/topic/Improvement.20beyond.20SMART.20scopes\" target=\"_blank\" title=\"https://chat.fhir.org/#narrow/stream/Security.20and.20Privacy/topic/Improvement.20beyond.20SMART.20scopes\">https://chat.fhir.org/#narrow/stream/Security.20and.20Privacy/topic/Improvement.20beyond.20SMART.20scopes</a></p>",
        "id": 153951247,
        "sender_full_name": "John Moehrke",
        "timestamp": 1523041475
    },
    {
        "content": "<p>perhaps the build should start publishing all the examples in bulk data format</p>",
        "id": 153951269,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1523052249
    },
    {
        "content": "<p>I think the following use cases exist:</p>\n<ul>\n<li>preloading a server with a prepared set of resources (dev or production use)<ul>\n<li>migration from one information system to another  </li>\n</ul>\n</li>\n<li>periodic bulk migration from one server to another</li>\n<li>initial upload of a patient record (or clinic)</li>\n</ul>",
        "id": 153951270,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1523052385
    },
    {
        "content": "<p>For the latter, you're thinking about things like \"my clinic is merging with yours and I want to import a pile of patients' worth of data that sit next to the records you've already got\"?</p>",
        "id": 153951271,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1523052456
    },
    {
        "content": "<p>possible errors from the server:</p>\n<ul>\n<li>duplicate resource ids (server could re-assign on load: a choice to be made, or overwrite)</li>\n<li>unacceptable content</li>\n<li>unresolvable link (internal broken reference)</li>\n<li>authorization failure - can't upload that</li>\n</ul>",
        "id": 153951272,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1523052490
    },
    {
        "content": "<p>yes the latter.</p>",
        "id": 153951273,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1523052495
    },
    {
        "content": "<p>I don't see that the $import needs an API scope - it has to be understood in the data being uploaded. And <span class=\"user-mention\" data-user-id=\"191757\">@Christiaan Knaap</span> you have to deal with authorization for all but the first case.</p>",
        "id": 153951275,
        "sender_full_name": "Grahame Grieve",
        "timestamp": 1523052566
    },
    {
        "content": "<p>How about using this to import a blue button download?</p>",
        "id": 153951283,
        "sender_full_name": "Brian Postlethwaite",
        "timestamp": 1523052926
    },
    {
        "content": "<p>Migrating a patient record between systems.<br>\nDoing patient/prac match etc.<br>\nDon't really want to create a new set of org/practitioner resources if it can be avoided. Where I don't think this is something we do in the transaction batch processing.</p>",
        "id": 153951289,
        "sender_full_name": "Brian Postlethwaite",
        "timestamp": 1523053054
    },
    {
        "content": "<blockquote>\n<p>I think the following use cases exist:<br>\n* preloading a server with a prepared set of resources (dev or production use)<br>\n  * migration from one information system to another  <br>\n* periodic bulk migration from one server to another<br>\n* initial upload of a patient record (or clinic)</p>\n</blockquote>\n<p>Both the async pattern and bulk data retrieval aspects are also very useful when running Measure.$evaluate-measure on a large number of patients, e.g. the whole population.</p>",
        "id": 153951406,
        "sender_full_name": "Bas van den Heuvel",
        "timestamp": 1523254213
    },
    {
        "content": "<p>What happened to $import?  I don't see it in the IG but know it's out there somewhere.</p>",
        "id": 187861491,
        "sender_full_name": "Douglas DeShazo",
        "timestamp": 1581370927
    },
    {
        "content": "<p>Initial work is here: <a href=\"https://github.com/smart-on-fhir/bulk-import\" target=\"_blank\" title=\"https://github.com/smart-on-fhir/bulk-import\">https://github.com/smart-on-fhir/bulk-import</a></p>",
        "id": 187863462,
        "sender_full_name": "Dan Gottlieb",
        "timestamp": 1581372256
    },
    {
        "content": "<p>Ahh...thanks.</p>",
        "id": 187921688,
        "sender_full_name": "Douglas DeShazo",
        "timestamp": 1581434948
    }
]