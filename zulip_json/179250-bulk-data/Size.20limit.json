[
    {
        "content": "<p>Hi am new to bulk data export so this may be a childish question. Our server has close 500K Condition resources and I want to fetch all of them to figure out the population distribution across <code>Condition.code</code> so when I issue this bulk data request</p>\n<p><code>/$export?_outputFormat=ndjson&amp;_type=Condition&amp;_since=2020-01-01T00:00:00.000Z</code></p>\n<p>I get only 200 Condition resources with no ability to paginate to next 200, so is there a way to get all Condition resources in one bulk data export ?</p>",
        "id": 247157288,
        "sender_full_name": "dsh",
        "timestamp": 1627266261
    },
    {
        "content": "<p>I don't think it makes sense to change the <code>max_page_size: 200</code> in <code>application.yml</code> of the server to get bulk data export exporting everything <span aria-label=\"anguished\" class=\"emoji emoji-1f627\" role=\"img\" title=\"anguished\">:anguished:</span></p>",
        "id": 247157415,
        "sender_full_name": "dsh",
        "timestamp": 1627266447
    },
    {
        "content": "<p>any ideas?</p>",
        "id": 247176768,
        "sender_full_name": "dsh",
        "timestamp": 1627289241
    },
    {
        "content": "<p>Which server for implementation are you using?</p>",
        "id": 247193533,
        "sender_full_name": "Vassil Peytchev",
        "timestamp": 1627301381
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"192685\">Vassil Peytchev</span> <a href=\"#narrow/stream/179250-bulk-data/topic/Size.20limit/near/247193533\">said</a>:</p>\n<blockquote>\n<p>Which server for implementation are you using?</p>\n</blockquote>\n<p>JPA server 5.3.0</p>",
        "id": 247223147,
        "sender_full_name": "dsh",
        "timestamp": 1627315328
    },
    {
        "content": "<p>That is probably a HAPI server then? Assuming your page size is 200, you should get multiple files with 200 conditions in each of them.</p>\n<p>Or perhaps only 200 have been modified since 2020-01-01? Anyhow, if you want to get all the conditions, then try removing the <code>_since</code> parameter.</p>",
        "id": 247225170,
        "sender_full_name": "Vladimir Ignatov",
        "timestamp": 1627316196
    },
    {
        "content": "<p>First I tried without <code>_since</code> but it didn't work and there are about 500K Conditions resources modified since 2020/01/01 ... then frustratingly I increased the <code>max_page_size</code> parameter to 1 million to fetch all Conditions</p>",
        "id": 247225571,
        "sender_full_name": "dsh",
        "timestamp": 1627316393
    },
    {
        "content": "<p>I am not sure if this is a bug but if others can confirm and or tell me what I might be doing wrong that will help</p>",
        "id": 247225762,
        "sender_full_name": "dsh",
        "timestamp": 1627316476
    },
    {
        "content": "<p>Were you only getting a single file link in your export manifest (before increasing the limit)?</p>",
        "id": 247225986,
        "sender_full_name": "Vladimir Ignatov",
        "timestamp": 1627316578
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"193731\">Vladimir Ignatov</span> <a href=\"#narrow/stream/179250-bulk-data/topic/Size.20limit/near/247225986\">said</a>:</p>\n<blockquote>\n<p>Were you only getting a single file link in your export manifest (before increasing the limit)?</p>\n</blockquote>\n<p>Yes and that was the weird part</p>",
        "id": 247226375,
        "sender_full_name": "dsh",
        "timestamp": 1627316756
    },
    {
        "content": "<p>after I increased the limit I got about 418 links</p>",
        "id": 247226549,
        "sender_full_name": "dsh",
        "timestamp": 1627316851
    },
    {
        "content": "<ol>\n<li>With 500K records and limit of 200 you should have gotten 2.5K links (if they fit into the manifest response size limit)</li>\n<li>With 500K records and limit of 1M you should have gotten 1 link to file with 500K rows</li>\n</ol>\n<p>That is just the simple math without the internal implementation details that could affect how pagination really works. I would suggest going to the HAPI GitHub and searching for this issue (and maybe posting new one if you don't find anything)</p>",
        "id": 247227428,
        "sender_full_name": "Vladimir Ignatov",
        "timestamp": 1627317292
    },
    {
        "content": "<p><span class=\"user-mention silent\" data-user-id=\"193731\">Vladimir Ignatov</span> <a href=\"#narrow/stream/179250-bulk-data/topic/Size.20limit/near/247227428\">said</a>:</p>\n<blockquote>\n<ol>\n<li>With 500K records and limit of 200 you should have gotten 2.5K links (if they fit into the manifest response size limit)</li>\n<li>With 500K records and limit of 1M you should have gotten 1 link to file with 500K rows</li>\n</ol>\n<p>That is just the simple math without the internal implementation details that could affect how pagination really works. I would suggest going to the HAPI GitHub and searching for this issue (and maybe posting new one if you don't find anything)</p>\n</blockquote>\n<p>your logic makes sense ... but that's not how the server behaved ... this may be a bug ... I will search in GitHub</p>",
        "id": 247227562,
        "sender_full_name": "dsh",
        "timestamp": 1627317362
    },
    {
        "content": "<p>You could also try asking this question over in the <a class=\"stream\" data-stream-id=\"179167\" href=\"/#narrow/stream/179167-hapi\">#hapi</a> stream (if that is what you are using), which may catch the attention of someone that knows the specifics of its bulk data implementation.</p>",
        "id": 247230220,
        "sender_full_name": "Robert Scanlon",
        "timestamp": 1627318598
    }
]