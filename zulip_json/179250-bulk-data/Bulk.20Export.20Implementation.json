[
    {
        "content": "<p>For one of our demonstrations we needed a bulk server supporting <code>_typeFilter</code> in <code>$export</code> and since I could not find any publicly-available servers with that capability, I hastily put together a bulk export service over the past few days which supports that parameter. This is highly experimental but I thought I'd share it here FWIW in case other groups may need something like this for the May Connectathon. <br>\nNote that this <em>not</em> a FHIR server and it works based on a configurable list of backed FHIR servers from which it fetches the resources using FHIR REST API. So, effectively,  it's a proxy which can be set in front of one or more existing FHIR servers to provide bulk export functionality.<br>\nSource code: <a href=\"https://github.com/mojitoholic/hotaru-swarm\" target=\"_blank\" title=\"https://github.com/mojitoholic/hotaru-swarm\">https://github.com/mojitoholic/hotaru-swarm</a><br>\nThere's a test sever deployed on heroku here:  <a href=\"https://hotaru-swarm.herokuapp.com/\" target=\"_blank\" title=\"https://hotaru-swarm.herokuapp.com/\">https://hotaru-swarm.herokuapp.com/</a></p>",
        "id": 163773090,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1555715476
    },
    {
        "content": "<p>How cool! I really like the proxy architecture for this kind of prototype. (Also I think this is the first Elixir project I've seen for FHIR.)</p>",
        "id": 163774047,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1555716656
    },
    {
        "content": "<p>It'd be interesting to think about how to get results incrementally into a db without having to accumulate everything in memory across all requests/servers.</p>",
        "id": 163774370,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1555717055
    },
    {
        "content": "<p>we use chunked encoding for this - <a href=\"https://docs.aidbox.app/api/bulk-api\" target=\"_blank\" title=\"https://docs.aidbox.app/api/bulk-api\">https://docs.aidbox.app/api/bulk-api</a> . Server and client implementations can be done with constant memory usage. May be something like this can be part of spec?!</p>",
        "id": 163793900,
        "sender_full_name": "nicola (RIO/SS)",
        "timestamp": 1555749238
    },
    {
        "content": "<p>as well i can implement bulk api with filter in aidbox for connectathon</p>",
        "id": 163794071,
        "sender_full_name": "nicola (RIO/SS)",
        "timestamp": 1555749509
    },
    {
        "content": "<p>Very neat project <span class=\"user-mention\" data-user-id=\"191920\">@Mohammad Jafari</span> ! <span class=\"user-mention\" data-user-id=\"193731\">@Vladimir Ignatov</span> weren't you also working on a bulk data proxy server?</p>",
        "id": 163804708,
        "sender_full_name": "Dan Gottlieb",
        "timestamp": 1555769008
    },
    {
        "content": "<p>Controlled buffering (and even file size for that matter) was not a priority for me at this point considering the purpose of this rapid prototype. But I can definitely add that if there's interest in the community to use Hotaru Swarm in future â€“Elixir has some very good tools, like <code>Stream</code>, <code>GenStage</code>, and <code>Flow</code> which makes that easy to implement.</p>",
        "id": 163811480,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1555780571
    },
    {
        "content": "<p>My main feedback at this point (and I'm going to write this up in a blog post) is that we'd probably be better off if we use the existing FHIR REST API for CRUD-ing export  jobs. A FHIR resource, say named <code>BatchJob</code>, can be created to trigger a an export, fetched for checking the status of the export, and eventually updated by the server to reflect the results once the task completed. The client can read/delete this resource. All of these can take place under existing FHIR REST API operations (plus more, e.g. versioning, search) and subject to existing FHIR authorization and audit mechanisms; this way the specs will only need to define the <code>BulkJob</code> resource structure and the expected behaviour under the hood for fulfilling it. Moreover, there is much less cognitive overhead for developers n terms of how to store and keep track of jobs and the access API. <span class=\"user-mention\" data-user-id=\"191315\">@Josh Mandel</span></p>",
        "id": 163811800,
        "sender_full_name": "Mohammad Jafari",
        "timestamp": 1555781223
    },
    {
        "content": "<p>Thanks <span class=\"user-mention\" data-user-id=\"191920\">@Mohammad Jafari</span> . This is definitely something we talked about as we were defining the export API, though in the end having an async pattern for issuing <em>any</em> FHIR API call felt more general-purpose. It's worth continuing to discuss as we review ballot comments, so I hope you'll share a link to your blog post when it's up.</p>",
        "id": 163812003,
        "sender_full_name": "Josh Mandel",
        "timestamp": 1555781573
    }
]